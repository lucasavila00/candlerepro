{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1996,  4937,  7719,  2648,   102,     0,     0,     0,     0],\n",
      "        [  101,  2070,  2060,  3793,  2008,  2097,  2224, 11687,  4667,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Sentence embeddings: tensor([[-0.5609, -1.5735,  0.4297,  ...,  1.5557,  0.3807,  0.5673],\n",
      "        [ 0.0375,  0.1586, -0.1318,  ..., -0.0153,  0.0603,  0.1512]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = [\"The cat sits outside\", \"some other text that will use padding\"]\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-base-en-v1.5')\n",
    "model = AutoModel.from_pretrained('BAAI/bge-base-en-v1.5')\n",
    "model.eval()\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "print(encoded_input)\n",
    "# for s2p(short query to long passage) retrieval task, add an instruction to query (not add instruction for passages)\n",
    "# encoded_input = tokenizer([instruction + q for q in queries], padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "    # Perform pooling. In this case, cls pooling.\n",
    "    sentence_embeddings = model_output[0][:, 0]\n",
    "# normalize embeddings\n",
    "print(\"Sentence embeddings:\", sentence_embeddings)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings: tensor([[-0.0362, -0.1016,  0.0278,  ...,  0.1005,  0.0246,  0.0366],\n",
      "        [ 0.0024,  0.0101, -0.0084,  ..., -0.0010,  0.0038,  0.0096]])\n"
     ]
    }
   ],
   "source": [
    "sentence_embeddings2 = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n",
    "print(\"Sentence embeddings:\", sentence_embeddings2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
